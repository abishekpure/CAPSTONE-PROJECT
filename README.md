# Voice-Emotion-Detection-using-different-models
PROBLEM STATEMENT

The purpose is to recognize the emotion and affective state of the speaker from his/her speech signal.

DATASET USED

We have used the RAVDESS dataset in this project.It is one of the most common datasets used for this exercise by others. It is highly preferred because of its quality of speeches, recordings and it has 24 actors of different genders.Each of the 24 professional actors that make up the RAVDESS performs 104 distinct vocalizations representing a range of emotions, including joyful, sad, angry, afraid, surprised, disgusted, calm, and neutral.

AIM

The project's aim is to assess how well various emotion recognition methods function when there is additional noise and shift in the dataset. The goal of the research is to find the most reliable and efficient model for emotion recognition in noisy and shifting data as well as approaches to increase the model's effectiveness.The project would include choosing and putting different emotion recognition models, including decision trees, KNN, LSTM, GRU, MLPC, and CNN, into practice. To imitate real-world circumstances, the models would be trained and tested on a dataset that has added noise and shift.

OBJECTIVE

This project’s objective is to examine the performance of various emotion recognition algorithms in noisy and shifting environments in order to determine which model is the most reliable and accurate under these conditions.Under these circumstances, the purpose of an emotion detection system using several models would be to appropriately categorize emotions despite the additional noise and shift in the data.Identifying the most reliable and efficient model for emotion recognition in shifting and noisy environments is the key point to an emotion detection system. We can discover the best method for emotion recognition in noisy and shifting environments by evaluating the performance of various models, highlighting the advantages and disadvantages of each model.





